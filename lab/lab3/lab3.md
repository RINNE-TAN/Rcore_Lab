# Lab 3

lab-3+整体来说难度并不大，但是由于代码中涉及了后面线程相关的部分，理解起来比较麻烦，先写下一部分理解

## 几个重要概念：

### 物理地址内存相关

位运算在这些概念中相当重要，这些概念全都是基于位运算的基础上实现的

物理内存，在qemu虚拟出来的一片连续地址空间，又叫DARM，其中opensbi也存放在这上面，范围从0x80000000-0x88000000

物理地址 PhysicalAdress,是封装了usize的元组结构体

物理页号 PhysicalPageNumber,用来管理4k大小的物理内存，又写作ppn

物理地址和物理页号之间的转换：

- 通过地址可以直接按字节位移得到页号
- 通过页号和页内偏移可以得到地址（使用相对较少），页内偏移即**page_offset**,整个概念比较重要，在后面也会提到
- 通过页号得到页的起始地址

FrameTracker:名字比较难解释，可以理解成对页面的监视器，利用了rust的所有权机制，在drop的时候自动回收，并且调用回调函数，是对ppn的一个封装

### 虚拟地址相关

虚拟地址 VirtualAddress布局为vpn2 vpn1 vpn0 page_offset

所占字节数分别为9 9 9 12，其中这里的page_offset就是上面提到的page_offset

页表项可以看作一个键值对，其中key是vpn，value是ppn + flag,flag用来记录一个物理页的信息，如是否可读/写，最近是否被访问等等，其中dirty和access位可以用于页面转置算法

三级页表：一个三级页表最好看成一个整体，一个三级页表可以用satp中的值来表示

satp寄存器 -> 根页表 -> 三级页表 -> 512个二级页表 -> 512*512个一级页表

其中一个一级页表控制4k内存（即一个物理页），以此类推一个二级页表控制2mb内存，一个根页表控制1GB内存，而且当satp寄存器的值改变，意味着根页表改变，整个页表的树结构也变了，这时候三级页表映射到了另外一片1GB大小的物理内存，要刷新TLB来达到快速访问的要求。

内存段是对若干虚拟页区间的抽象，即Segment，这在初始化内核的时候会有用
### 页面置换算法

由于涉及了多线程操作，一开始还是比较懵的，在线程中会有一部分和内存相关的工作，一个是在初始化线程的时候要分配一段内存段作为线程的栈，同时线程中的Mapping保存了某个线程中的内存映射关系，同时这里也用了Tracker机制，在线程销毁的时候，线程申请的物理页等资源也会一并销毁

线程进程的一个简单理解：**进程代表了静态资源，进程代表了动态特性**

至于测试，lab-3+已经封装好了一个用户程序swap_test
源码如下
```rust
pub unsafe fn main() -> usize {
    let mut i = 0;
    while i < array.len() {
        array[i] = i;
        i = i + 1;
    }
    for i in 0..array.len() {
        assert_eq!(i, array[i]);
    }
    println!("\x1b[32mtest passed\x1b[0m");
    0
}
```
在user/bin/swap_test.rs当中
只能说目前的页面置换测试是相当不准确的，在一个大数组中顺序访问，页面被访问的顺序是固定有序的，在完成了时钟置换算法后发现并没有降低多少缺页率，其实这样子的测试也比较难模拟真实的内存使用情况？但是如何模拟页面使用也是一个难题，如果随机去使用的话，任何页面置换算法都失去意义了，所以这些算法设计的前提基本上都是

**最近被修改/访问的页面将来被修改/访问的概率也比较大**

**算法的设计**

在页表项中有flag标记，其中Access位表示该映射代表的物理内存最近有被读/写，Dirty位表示该映射代表的物理内存最近有被写，这两位都可以提高该映射保留优先级（即更难被置换走），而Dirty的优先级又高于Access位，因为Dirty被标记意味着发生写操作，要进行磁盘操作，故优先级较高

Clock算法流程
1. 判断指针指向的节点是否Access位和Dirty位均为0，如果是则将该节点置换出去,如果不是，则将该节点Access位标记为0。
2. 重复1直到绕表盘一周
3. 如果此时还未找到，判断指针指向的节点是否Access位和Dirty位均为0，如果是则将该节点置换出去,如果不是，则将该节点Dirty位标记为0。
4. 此时必能找到两个位置均为0的节点，将该节点置换出去。
5. 置换后，指针移向下一位。

但是由于算法的设计基于前面的假设，这样子的假设也比较难体现在测试中，故Clock算法和FIFO的优劣就很难比较出来，实验结果如下：

1. 在分配线程栈的时候，Clock缺页率为FIFO的一半。
2. 在lab提供的用户程序中FIFO发生缺页中断次数为1144次，Clock发生缺页中断的次数为1133次，提升仅仅为0.96%。
3. 在修改测试为每次访问内存都是随机访问，两者的缺页率都将近100%，即每次访问都会导致缺页中断！
4. 缺页中断如果只用Dirty位来判断将导致缺页次数过多，如果只用Access位来判断缺页次数有降低，如果用Dirty和Access一起判断则对效率没有提升，事实上在测试几次后我发现对dirty位设置的时机不太确定，暂时忽略了这位。

可以说第3点是比较出乎意料的，当时由于FIFO和Clock算法都是尽量保留最近使用的页表项，而我设置的伪随机测试，相对跨度比较大，很难命中之前用过的内存，故缺页率高也相对正常。测试代码如下：
```rust
    let mut step = 0;
    let test_times = 0;
    while test_times < 1000 {
        step = step + test_times;
        let i = step % array.len();
        array[i] = i;
    }
```
在测试中这个循环的1000次中发生了990多次页面中断
不过最终相比于FIFO还是有提升并且能通过测试的